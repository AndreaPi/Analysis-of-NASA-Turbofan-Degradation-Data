---
title: "Exploratory Data Analysis of NASA Turbofan Engine Degradation Data"
author: "Andrea Panizza"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    keep_md: yes
params:
  output_dir: ../output
---

<style>
p.caption {
  font-size: 0.8em;
}
</style>  


**EDA is described in Chapter 7 of R4DS**

```{r setup, include=FALSE}
source("EDA_rmd_setup.r")
output_dir <- params$output_dir # needs to be in the Rmd file

```

## Read data 

**Data import is described in Chapter 11 of R4DS.**
Data taken from [NASA Ames Prognostic Center](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/). Specifically, dataset 6 **Turbofan Engine Degradation Simulation Data Set**. Four datasets: we concentrate on data set `FD001` for this analysis.

 * three data sets: a training set, a test set, a set of Remaining Useful Life (RUL) values for each engine in the test set
 * Goal: predict the RUL for each engine in the test set, using an algorithm trained on the training set
 * Only look at training set for simplicity

```{r}
file_name <- "train_FD001.txt"
data_path <- file.path(data_dir, file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))

glimpse(train_set)
```

 * engine number
 * time (in cycles)
 * operating setting 1
 * operating setting 2
 * operating setting 3
 * sensor 1
 * sensor 2
 * ....
 * sensor 21
 
## Exploratory Data Analysis
### Summary statistics
 
 * name variables
 * convert `engine` to a factor
 * add a time to event variable
 * create some basic statistical summaries
 
```{r}
var_names <- c("engine", "cycles", "op_setting_1", "op_setting_2", "op_setting_3",
               paste0("sensor_", 1:21))
names(train_set) <- var_names

train_set$engine <- factor(train_set$engine)

# add a Time to Event variable
add_tte <- function(dataset){
  dataset %<>% group_by(engine) %>% mutate(tte = max(cycles) - cycles) %>% ungroup
}

train_set <- add_tte(train_set)


```

```{r, results="asis"}

stats_train <- skim(train_set)
kable(stats_train)

```

 * 100 engines
 * ** no missing values** (simulated data)
 * some variables have a standard deviation of 0, and they can be dropped
 
```{r}

constants <- stats_train %>% filter(stat == "sd" & value == 0)
train_set %<>% select(-one_of(constants$variable))

```


### Normalize data

```{r}
train_set_unscaled <- train_set

index <- !(names(train_set) %in% c("engine", "cycles", "tte"))
temp <- scale(train_set[, index])
train_set[, index] <- temp

means                <- attr(temp, "scaled:center")
standard_deviations  <- attr(temp, "scaled:scale")

```

### Distribution of time-to-event

Look at distribution of tte in training set:

```{r}

tte <- train_set %>% select(engine, cycles, tte) %>% group_by(engine) %>%
  summarize(TTE = tte[1])

nbins = nclass.FD(tte$TTE)
ggplot(tte, aes(x = TTE, y = ..density..)) +
  geom_histogram(col = "red", fill = "green", alpha = 0.2, bins = nbins) +
  geom_density(col = "red", size = 1)

mean_tte <- mean(tte$TTE)
sd_tte   <- sd(tte$TTE)
normal_percentile_975 <- qnorm(p = 0.975, mean_tte, sd_tte)
actual_percentile_975 <- quantile(tte$TTE, probs = 0.975) 
normal_percentile_975
actual_percentile_975

```


 * no "infant mortality": all engines ran for at least `r min(tte$TTE)` days
 * distribution is fairly right-skewed. It looks like we have more engine with a longer than average life, than we would expect with a normal distribution
 
### Plot all time series

Operational settings first:

```{r}

op_settings <- train_set %>% select(engine, cycles, starts_with("op")) %>%
  gather(key = setting, value = measurement, -engine, -cycles)

ggplot(op_settings, aes(x = cycles, y =  measurement)) +
  geom_line(aes(group = engine), alpha = 0.1) +
  geom_smooth(se = FALSE) +
  facet_wrap(~ setting, scales = "free_y")

```

* `op_setting_1` seems to randomly oscillate
* `op_setting_2`, averaged over all time series, gradually increases with time, slowly at first and then faster at some point in time. 
* This might be related with the failure of the engines (all engines in the training set fail at some time). 
* `op_setting_2` is fairly quantized.


Next, sensors data:
```{r}

sensors <- train_set %>% select(-starts_with("op"), -tte) %>%
  gather(key = sensor, value = measurement, -engine, -cycles)

ggplot(sensors, aes(x = cycles, y =  measurement)) +
  geom_line(aes(group = engine), alpha = 0.025) +
  facet_wrap(~ sensor, scales = "free_y")
```

* lot of signal in the sensors. For example, the sooner `sensor_11` starts increasing, the shorter the residual life of the engine.
* also a lot of noise (large oscillations), and correlation among sensors. For example, `sensor_11` and `sensor_4`, or `sensor_9` and `sensor_14` seem to have the same trend, at least averaged across all engines.
* `sensor_17` measurements are fairly quantized, but they seem to carry some signal.
* `sensor_6`  seems to oscillate randomly among `r length(unique(train_set_unscaled$sensor_6))` values, so it's probably useless.

### Plot a sample of time series
Now look at a sample of engines, to see individual, rather than global trends:

```{r}
sample_train_set <- train_set %>% filter(engine %in% sample(engine, 10))

sample_train_set_tall <- sample_train_set %>% 
gather(key = sensor, value = measurement, -engine, -cycles, -starts_with("op"), -tte)

ggplot(sample_train_set_tall, aes(x = cycles, y =  measurement, color = engine)) +
geom_line() +
geom_smooth(se = FALSE) +
scale_color_viridis(discrete = TRUE) +
facet_wrap(~ sensor, scales = "free_y")
```

This suggests that some sensors are correlated not only at a population level, i.e., averaging the sensor signals across all engines, but even for a single engine (compare `sensor_11` with `sensor_4` and `sensor_9` with `sensor_14` for the yellow line).

This concludes our EDA.
